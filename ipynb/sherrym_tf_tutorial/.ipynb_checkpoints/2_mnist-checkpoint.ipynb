{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use shift-enter to execute a code block and move to the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2786635865932250728]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.1 Import libraries.\n",
    "import math\n",
    "import os\n",
    "import six\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2.2 Define some constants.\n",
    "# The MNIST dataset has 10 classes, representing the digits 0 through 9.\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MNIST images are always 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "\n",
    "# Batch size. Must be evenly dividable by dataset sizes.\n",
    "BATCH_SIZE = 100\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "# Number of units in hidden layers.\n",
    "HIDDEN1_UNITS = 128\n",
    "HIDDEN2_UNITS = 32\n",
    "\n",
    "# Maximum number of training steps.\n",
    "MAX_STEPS = 2000\n",
    "\n",
    "# Directory to put the training data.\n",
    "TRAIN_DIR=\"/tmp/mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am running Python 2!\n"
     ]
    }
   ],
   "source": [
    "if six.PY3:\n",
    "    print('I am running Python 3!')\n",
    "elif six.PY2:\n",
    "    print('I am running Python 2!')\n",
    "else:\n",
    "    print('Python version uncertain...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Get input data: get the sets of images and labels for training, validation, and\n",
    "# test on MNIST.\n",
    "data_sets = mnist.read_data_sets(TRAIN_DIR, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets.train._labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 135.,  195.,  285.,  346.,  474.,  540.,  662.,  725.,  820.,\n",
       "         874.,  799.,  791.,  742.,  677.,  545.,  464.,  335.,  238.,\n",
       "         197.,  156.]),\n",
       " array([ -1.99953830e+00,  -1.79959401e+00,  -1.59964973e+00,\n",
       "         -1.39970544e+00,  -1.19976115e+00,  -9.99816865e-01,\n",
       "         -7.99872577e-01,  -5.99928290e-01,  -3.99984002e-01,\n",
       "         -2.00039715e-01,  -9.54270363e-05,   1.99848861e-01,\n",
       "          3.99793148e-01,   5.99737436e-01,   7.99681723e-01,\n",
       "          9.99626011e-01,   1.19957030e+00,   1.39951459e+00,\n",
       "          1.59945887e+00,   1.79940316e+00,   1.99934745e+00]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188ca090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# truncated_normal discard values beyond 2\\sigma and resamples\n",
    "a = tf.truncated_normal([10000, 1])\n",
    "b = tf.Session().run(a)\n",
    "plt.hist(b, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.4 Build inference graph.\n",
    "def mnist_inference(images, hidden1_units, hidden2_units):\n",
    "    \"\"\"Build the MNIST model up to where it may be used for inference.\n",
    "    Args:\n",
    "        images: Images placeholder.\n",
    "        hidden1_units: Size of the first hidden layer.\n",
    "        hidden2_units: Size of the second hidden layer.\n",
    "    Returns:\n",
    "        logits: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([IMAGE_PIXELS, hidden1_units],\n",
    "                                stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))), # why normalize?\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden1_units]),\n",
    "                             name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)\n",
    "    # Hidden 2\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hidden1_units, hidden2_units],\n",
    "                                stddev=1.0 / math.sqrt(float(hidden1_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden2_units]),\n",
    "                             name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    # Linear\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hidden2_units, NUM_CLASSES],\n",
    "                                stddev=1.0 / math.sqrt(float(hidden2_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([NUM_CLASSES]),\n",
    "                             name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    "\n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"inference.pbtxt\", as_text=True)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.5 Build training graph.\n",
    "def mnist_training(logits, labels, learning_rate):\n",
    "    \"\"\"Build the training graph.\n",
    "\n",
    "    Args:\n",
    "        logits: Logits tensor, float - [BATCH_SIZE, NUM_CLASSES].\n",
    "        labels: Labels tensor, int32 - [BATCH_SIZE], with values in the\n",
    "          range [0, NUM_CLASSES).\n",
    "        learning_rate: The learning rate to use for gradient descent.\n",
    "    Returns:\n",
    "        train_op: The Op for training.\n",
    "        loss: The Op for calculating loss.\n",
    "    \"\"\"\n",
    "    # Create an operation that calculates loss.\n",
    "    labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits, labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    # Create the gradient descent optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"train.pbtxt\", as_text=True)\n",
    "\n",
    "    return train_op, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2.6 Build the complete graph for feeding inputs, training, and saving checkpoints.\n",
    "mnist_graph = tf.Graph()\n",
    "with mnist_graph.as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "    images_placeholder = tf.placeholder(tf.float32)                                       \n",
    "    labels_placeholder = tf.placeholder(tf.int32)\n",
    "    tf.add_to_collection(\"images\", images_placeholder)  # Remember this Op.\n",
    "    tf.add_to_collection(\"labels\", labels_placeholder)  # Remember this Op.\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = mnist_inference(images_placeholder,\n",
    "                             HIDDEN1_UNITS,\n",
    "                             HIDDEN2_UNITS)\n",
    "    tf.add_to_collection(\"logits\", logits)  # Remember this Op.\n",
    "\n",
    "    # Add to the Graph the Ops that calculate and apply gradients.\n",
    "    train_op, loss = mnist_training(logits, labels_placeholder, 0.01)\n",
    "\n",
    "    # Add the variable initializer Op.\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Uncomment the following line to see what we have constructed.\n",
    "    # tf.train.write_graph(tf.get_default_graph().as_graph_def(),\n",
    "    #                      \"/tmp\", \"complete.pbtxt\", as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2.7 Run training for MAX_STEPS and save checkpoint at the end.\n",
    "with tf.Session(graph=mnist_graph) as sess:\n",
    "    # Run the Op to initialize the variables.\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the training loop.\n",
    "    for step in xrange(MAX_STEPS):\n",
    "        # Read a batch of images and labels.\n",
    "        images_feed, labels_feed = data_sets.train.next_batch(BATCH_SIZE)\n",
    "\n",
    "        # Run one step of the model.  The return values are the activations\n",
    "        # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "        # inspect the values of your Ops or variables, you may include them\n",
    "        # in the list passed to sess.run() and the value tensors will be\n",
    "        # returned in the tuple from the call.\n",
    "        _, loss_value = sess.run([train_op, loss],\n",
    "                                 feed_dict={images_placeholder: images_feed,\n",
    "                                            labels_placeholder: labels_feed})\n",
    "\n",
    "        # Print out loss value.\n",
    "        if step % 1000 == 0:\n",
    "            print('Step %d: loss = %.2f' % (step, loss_value))\n",
    "\n",
    "    # Write a checkpoint.\n",
    "    checkpoint_file = os.path.join(TRAIN_DIR, 'checkpoint')\n",
    "    saver.save(sess, checkpoint_file, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2.8 Run evaluation based on the saved checkpoint.\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    saver = tf.train.import_meta_graph(\n",
    "        os.path.join(TRAIN_DIR, \"checkpoint-1999.meta\"))\n",
    "    saver.restore(\n",
    "        sess, os.path.join(TRAIN_DIR, \"checkpoint-1999\"))\n",
    "\n",
    "    # Retrieve the Ops we 'remembered'.\n",
    "    logits = tf.get_collection(\"logits\")[0]\n",
    "    images_placeholder = tf.get_collection(\"images\")[0]\n",
    "    labels_placeholder = tf.get_collection(\"labels\")[0]\n",
    "    \n",
    "    # Add an Op that chooses the top k predictions.\n",
    "    eval_op = tf.nn.top_k(logits)\n",
    "    \n",
    "    # Run evaluation.\n",
    "    images_feed, labels_feed = data_sets.validation.next_batch(EVAL_BATCH_SIZE)\n",
    "    imgplot = plt.imshow(np.reshape(images_feed, (28, 28)))\n",
    "    prediction = sess.run(eval_op,\n",
    "                          feed_dict={images_placeholder: images_feed,\n",
    "                                     labels_placeholder: labels_feed})\n",
    "    print(\"Ground truth: %d\\nPrediction: %d\" % (labels_feed, prediction.indices[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>Back to [1_linear_regression_model.ipynb](1_linear_regression_model.ipynb).</p>\n",
    "<p>Next to [Bonus Lab](extras/extras_0_deepdream.ipynb).</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
